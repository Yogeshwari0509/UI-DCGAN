{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4CqcR92z1a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e32387e6-9290-450f-b802-b83b6b4688de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok streamlit tensorflow diffusers torch -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GDLq-Ftz2K7",
        "outputId": "42160d06-7b2d-4107-cc65-bf3894a0add7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model1.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "import h5py\n",
        "import json\n",
        "\n",
        "SEED_SIZE = 100\n",
        "EMBEDDING_SIZE = 300\n",
        "\n",
        "def clean_h5_model(file_path):\n",
        "    with h5py.File(file_path, 'r+') as h5_file:\n",
        "        model_config = h5_file.attrs['model_config']\n",
        "        if isinstance(model_config, bytes):\n",
        "            model_config = model_config.decode('utf-8')\n",
        "        model_config = json.loads(model_config)\n",
        "\n",
        "        for layer in model_config['config']['layers']:\n",
        "            if layer['class_name'] == 'Conv2DTranspose' and 'groups' in layer['config']:\n",
        "                del layer['config']['groups']\n",
        "        h5_file.attrs['model_config'] = json.dumps(model_config).encode('utf-8')\n",
        "\n",
        "@st.cache_resource\n",
        "def load_gan_model(model_path):\n",
        "    clean_h5_model(model_path)\n",
        "    return tf.keras.models.load_model(model_path)\n",
        "\n",
        "def generate_image(gan_model, text_input):\n",
        "    noise = tf.random.normal([1, SEED_SIZE])\n",
        "    words = text_input.lower().split()\n",
        "    test_embeddings = np.zeros((1, EMBEDDING_SIZE), dtype=np.float32)\n",
        "    count = 0\n",
        "\n",
        "    for word in words:\n",
        "        if word in glove_embeddings:\n",
        "            test_embeddings[0] += glove_embeddings[word]\n",
        "            count += 1\n",
        "\n",
        "    if count > 0:\n",
        "        test_embeddings[0] /= count\n",
        "\n",
        "    generated_image = gan_model.predict([noise, test_embeddings], verbose=0)\n",
        "    generated_image = 0.5 * generated_image + 0.5\n",
        "    image = Image.fromarray((generated_image[0] * 255).astype(np.uint8))\n",
        "\n",
        "    # Assign the image to low_quality_image before resizing it\n",
        "    low_quality_image = image.resize((32, 32), Image.NEAREST)\n",
        "\n",
        "    return low_quality_image\n",
        "\n",
        "st.title('Text to Image Generator with GAN')\n",
        "\n",
        "model_path = '/content/text_to_image_generator_cub_character.h5'\n",
        "gan_model = load_gan_model(model_path)\n",
        "st.success(\"GAN model loaded successfully!\")\n",
        "\n",
        "glove_embeddings = np.load('/content/embedding_data.npy', allow_pickle=True)\n",
        "glove_embeddings = {item[0]: item[1] for item in glove_embeddings} if isinstance(glove_embeddings, np.ndarray) else glove_embeddings.item()\n",
        "st.success(\"GloVe embeddings loaded successfully!\")\n",
        "\n",
        "text_input = st.text_input(\"What image would you like to create?\")\n",
        "\n",
        "if text_input and gan_model:\n",
        "    generated_image = generate_image(gan_model, text_input)\n",
        "    refined_image = modify_image_with_stable_diffusion(generated_image, text_input)\n",
        "    st.image(refined_image, caption='Generated Image from GAN', use_column_width=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f56Fh-2Z2tjW",
        "outputId": "68c982ab-8e12-46e6-f360-4e42c464fea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok authtoken \"2n9XjbtbFcYEkuW3Y0SPoCsfe3J_YHtug7pETtB11smowxz1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBa6pPsn0OBC",
        "outputId": "ee93dc9e-a098-4126-e10c-bee420149c44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * ngrok tunnel \"https://0cc6-34-16-148-255.ngrok-free.app\" -> \"http://127.0.0.1:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.16.148.255:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2024-10-17 15:19:38.029802: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-17 15:19:38.069346: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-17 15:19:38.085845: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-17 15:19:39.401673: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1729178380.718894    7942 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1729178380.729982    7942 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1729178380.730249    7942 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1729178380.731041    7942 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1729178380.731369    7942 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1729178380.731586    7942 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1729178380.840411    7942 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "I0000 00:00:1729178380.840695    7942 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-10-17 15:19:40.840864: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1729178380.840973    7942 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1729178392.325900    7986 service.cc:146] XLA service 0xf1cb40057e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1729178392.325964    7986 service.cc:154]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "E0000 00:00:1729178393.598488    7986 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "E0000 00:00:1729178393.761693    7986 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
            "I0000 00:00:1729178394.046073    7986 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "scheduler/scheduler_config.json: 100% 345/345 [00:00<00:00, 1.71MB/s]\n",
            "model_index.json: 100% 511/511 [00:00<00:00, 2.59MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/pipeline_loading_utils.py:219: FutureWarning: You are loading the variant fp16 from stabilityai/stable-diffusion-2 via `revision='fp16'` even though you can load it via `variant=`fp16`. Loading model variants via `revision='fp16'` is deprecated and will be removed in diffusers v1. Please use `variant='fp16'` instead.\n",
            "  warnings.warn(\n",
            "text_encoder/model.safetensors not found\n",
            "Fetching 11 files:   0% 0/11 [00:00<?, ?it/s]\n",
            "tokenizer/tokenizer_config.json: 100% 815/815 [00:00<00:00, 5.68MB/s]\n",
            "\n",
            "tokenizer/merges.txt:   0% 0.00/525k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "text_encoder/config.json: 100% 624/624 [00:00<00:00, 3.35MB/s]\n",
            "\n",
            "\n",
            "unet/config.json: 100% 900/900 [00:00<00:00, 3.14MB/s]\n",
            "\n",
            "\n",
            "tokenizer/special_tokens_map.json: 100% 460/460 [00:00<00:00, 2.96MB/s]\n",
            "\n",
            "\n",
            "tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 7.65MB/s]\n",
            "\n",
            "pytorch_model.bin:   0% 0.00/681M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   0% 0.00/1.73G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "vae/config.json: 100% 602/602 [00:00<00:00, 3.57MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 3.98MB/s]\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   1% 10.5M/1.73G [00:00<00:47, 36.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   6% 10.5M/167M [00:00<00:03, 50.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:   2% 10.5M/681M [00:00<00:25, 26.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   1% 21.0M/1.73G [00:00<00:36, 47.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  13% 21.0M/167M [00:00<00:02, 71.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:   3% 21.0M/681M [00:00<00:17, 37.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   2% 31.5M/1.73G [00:00<00:30, 56.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  25% 41.9M/167M [00:00<00:01, 100MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   2% 41.9M/1.73G [00:00<00:24, 68.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:   5% 31.5M/681M [00:00<00:13, 48.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  38% 62.9M/167M [00:00<00:00, 118MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   3% 52.4M/1.73G [00:00<00:22, 75.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:   6% 41.9M/681M [00:00<00:10, 60.1MB/s]\u001b[A\n",
            "pytorch_model.bin:   8% 52.4M/681M [00:00<00:08, 70.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  50% 83.9M/167M [00:00<00:00, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   4% 62.9M/1.73G [00:00<00:21, 76.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:   9% 62.9M/681M [00:01<00:08, 76.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   5% 83.9M/1.73G [00:01<00:18, 89.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  63% 105M/167M [00:00<00:00, 113MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  12% 83.9M/681M [00:01<00:05, 102MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  75% 126M/167M [00:01<00:00, 117MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  15% 105M/681M [00:01<00:04, 116MB/s] \u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   6% 105M/1.73G [00:01<00:16, 97.1MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   7% 126M/1.73G [00:01<00:14, 108MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  88% 147M/167M [00:01<00:00, 117MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  18% 126M/681M [00:01<00:04, 116MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:   8% 147M/1.73G [00:01<00:13, 120MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin: 100% 167M/167M [00:01<00:00, 123MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "diffusion_pytorch_model.bin: 100% 167M/167M [00:01<00:00, 99.4MB/s]\n",
            "\n",
            "pytorch_model.bin:  25% 168M/681M [00:01<00:04, 120MB/s]\u001b[A\n",
            "pytorch_model.bin:  28% 189M/681M [00:02<00:03, 125MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  10% 168M/1.73G [00:02<00:18, 83.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  31% 210M/681M [00:02<00:03, 134MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  11% 189M/1.73G [00:02<00:15, 97.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  34% 231M/681M [00:02<00:03, 139MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  12% 210M/1.73G [00:02<00:14, 106MB/s] \u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  37% 252M/681M [00:02<00:03, 125MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  13% 231M/1.73G [00:02<00:13, 110MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  40% 273M/681M [00:02<00:03, 120MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  15% 252M/1.73G [00:02<00:13, 111MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  45% 304M/681M [00:02<00:02, 137MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  16% 273M/1.73G [00:02<00:14, 98.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  48% 325M/681M [00:03<00:02, 121MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  17% 294M/1.73G [00:03<00:14, 101MB/s] \u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  51% 346M/681M [00:03<00:02, 125MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  18% 315M/1.73G [00:03<00:12, 117MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  54% 367M/681M [00:03<00:02, 136MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  19% 336M/1.73G [00:03<00:10, 133MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  57% 388M/681M [00:03<00:02, 121MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  21% 357M/1.73G [00:03<00:12, 114MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  60% 409M/681M [00:03<00:02, 132MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  22% 377M/1.73G [00:03<00:10, 127MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  63% 430M/681M [00:03<00:01, 130MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  23% 398M/1.73G [00:03<00:10, 130MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  66% 451M/681M [00:04<00:01, 133MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  24% 419M/1.73G [00:04<00:09, 136MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  25% 440M/1.73G [00:04<00:09, 139MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  69% 472M/681M [00:04<00:01, 131MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  27% 461M/1.73G [00:04<00:09, 139MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  72% 493M/681M [00:04<00:01, 128MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  28% 482M/1.73G [00:04<00:09, 135MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  75% 514M/681M [00:04<00:01, 125MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  29% 503M/1.73G [00:04<00:09, 124MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  79% 535M/681M [00:04<00:01, 120MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  30% 524M/1.73G [00:04<00:08, 135MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  82% 556M/681M [00:04<00:01, 124MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  31% 545M/1.73G [00:04<00:08, 132MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  85% 577M/681M [00:05<00:00, 117MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  33% 566M/1.73G [00:05<00:08, 130MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  88% 598M/681M [00:05<00:00, 118MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  34% 587M/1.73G [00:05<00:08, 130MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  91% 619M/681M [00:05<00:00, 115MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  35% 608M/1.73G [00:05<00:09, 122MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  94% 640M/681M [00:05<00:00, 89.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  36% 629M/1.73G [00:05<00:13, 83.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  95% 650M/681M [00:06<00:00, 72.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  37% 640M/1.73G [00:06<00:15, 70.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  97% 661M/681M [00:06<00:00, 64.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  38% 650M/1.73G [00:06<00:16, 67.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  38% 661M/1.73G [00:07<00:42, 25.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin:  99% 671M/681M [00:07<00:00, 23.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  39% 682M/1.73G [00:07<00:28, 37.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "pytorch_model.bin: 100% 681M/681M [00:07<00:00, 86.2MB/s]\n",
            "Fetching 11 files:  27% 3/11 [00:08<00:27,  3.39s/it]\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  41% 713M/1.73G [00:07<00:16, 60.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  42% 734M/1.73G [00:08<00:12, 76.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  44% 755M/1.73G [00:08<00:10, 91.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  45% 776M/1.73G [00:08<00:08, 106MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  46% 797M/1.73G [00:08<00:07, 123MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  47% 818M/1.73G [00:08<00:07, 128MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  48% 839M/1.73G [00:08<00:06, 141MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  50% 860M/1.73G [00:08<00:05, 151MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  51% 881M/1.73G [00:08<00:05, 159MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  52% 902M/1.73G [00:09<00:05, 165MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  53% 923M/1.73G [00:09<00:04, 169MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  54% 944M/1.73G [00:09<00:04, 173MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  56% 965M/1.73G [00:09<00:04, 175MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  57% 986M/1.73G [00:09<00:04, 175MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  58% 1.01G/1.73G [00:11<00:19, 36.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  59% 1.03G/1.73G [00:13<00:41, 16.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  61% 1.06G/1.73G [00:14<00:25, 26.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  63% 1.09G/1.73G [00:14<00:16, 38.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  64% 1.11G/1.73G [00:14<00:12, 48.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  65% 1.13G/1.73G [00:14<00:10, 59.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  67% 1.15G/1.73G [00:14<00:07, 73.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  68% 1.17G/1.73G [00:14<00:06, 88.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  69% 1.20G/1.73G [00:14<00:05, 105MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  70% 1.22G/1.73G [00:14<00:04, 120MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  71% 1.24G/1.73G [00:15<00:03, 133MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  73% 1.26G/1.73G [00:15<00:03, 145MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  74% 1.28G/1.73G [00:15<00:02, 154MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  75% 1.30G/1.73G [00:15<00:02, 159MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  76% 1.32G/1.73G [00:15<00:02, 157MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  77% 1.34G/1.73G [00:15<00:02, 167MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  79% 1.36G/1.73G [00:15<00:02, 136MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  80% 1.38G/1.73G [00:16<00:02, 135MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  81% 1.41G/1.73G [00:17<00:06, 47.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  82% 1.43G/1.73G [00:17<00:05, 58.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  84% 1.45G/1.73G [00:17<00:06, 45.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  85% 1.48G/1.73G [00:18<00:03, 66.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  87% 1.50G/1.73G [00:18<00:02, 80.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  88% 1.52G/1.73G [00:18<00:02, 95.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  89% 1.54G/1.73G [00:18<00:01, 106MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  90% 1.56G/1.73G [00:18<00:01, 117MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  91% 1.58G/1.73G [00:18<00:01, 133MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  93% 1.60G/1.73G [00:18<00:00, 146MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  94% 1.63G/1.73G [00:18<00:00, 158MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  95% 1.65G/1.73G [00:19<00:00, 114MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  97% 1.68G/1.73G [00:19<00:00, 143MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin:  98% 1.70G/1.73G [00:19<00:00, 152MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "diffusion_pytorch_model.bin: 100% 1.73G/1.73G [00:19<00:00, 87.9MB/s]\n",
            "Fetching 11 files: 100% 11/11 [00:20<00:00,  1.82s/it]\n",
            "Loading pipeline components...:  20% 1/5 [00:00<00:02,  1.52it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Loading pipeline components...:  40% 2/5 [00:00<00:01,  2.92it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--stabilityai--stable-diffusion-2/snapshots/d75b612d366d802b1753960de862a9270c8d55f1/vae: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--stabilityai--stable-diffusion-2/snapshots/d75b612d366d802b1753960de862a9270c8d55f1/vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...:  80% 4/5 [00:01<00:00,  2.40it/s]An error occurred while trying to fetch /root/.cache/huggingface/hub/models--stabilityai--stable-diffusion-2/snapshots/d75b612d366d802b1753960de862a9270c8d55f1/unet: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--stabilityai--stable-diffusion-2/snapshots/d75b612d366d802b1753960de862a9270c8d55f1/unet.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "Loading pipeline components...: 100% 5/5 [00:09<00:00,  1.85s/it]\n",
            "100% 10/10 [00:03<00:00,  2.51it/s]\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import threading\n",
        "from pyngrok import ngrok\n",
        "\n",
        "port = 8501\n",
        "\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(f\" * ngrok tunnel \\\"{public_url}\\\" -> \\\"http://127.0.0.1:{port}\\\"\")\n",
        "\n",
        "!streamlit run model.py &\n",
        "\n",
        "while True:\n",
        "    pass\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}